{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次總共訓練了4個神經網路：\n",
    "\n",
    "第一個神經網路用最原始loss function使用mse，激活函數使用sigmoid\n",
    "\n",
    "第二個神經網路loss function換成適合多分類問題的cross entropy\n",
    "\n",
    "第三個神經網路除了loss function換成適合多分類問題的cross entropy外，將激活函數換成鼎鼎大名的relu\n",
    "\n",
    "第四個神經網路為了防止overfitting的問題，加入了Dropout跟early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從keras讀入mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入、輸出資料整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出做one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train ,10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[9487]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 打造神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2層隱藏層\n",
    "\n",
    "第一層500個神經元\n",
    "\n",
    "第二層250個神經元\n",
    "\n",
    "隱藏層Activation function用sigmoid\n",
    "\n",
    "輸出層Activation function用softmax(softmax適合多分類問題，將神經元輸出壓縮到0~1之間)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100,input_dim = 784))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(250))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2510      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 256,760\n",
      "Trainable params: 256,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0895 - acc: 0.1720 - val_loss: 0.0885 - val_acc: 0.2890\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0867 - acc: 0.2557 - val_loss: 0.0836 - val_acc: 0.2865\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0783 - acc: 0.3147 - val_loss: 0.0734 - val_acc: 0.3975\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0675 - acc: 0.4663 - val_loss: 0.0604 - val_acc: 0.6108\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0540 - acc: 0.6461 - val_loss: 0.0449 - val_acc: 0.7322\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0393 - acc: 0.7733 - val_loss: 0.0308 - val_acc: 0.8615\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0279 - acc: 0.8581 - val_loss: 0.0208 - val_acc: 0.9007\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0214 - acc: 0.8824 - val_loss: 0.0168 - val_acc: 0.9113\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0186 - acc: 0.8914 - val_loss: 0.0156 - val_acc: 0.9093\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0170 - acc: 0.8976 - val_loss: 0.0139 - val_acc: 0.9197\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0161 - acc: 0.9023 - val_loss: 0.0127 - val_acc: 0.9228\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0153 - acc: 0.9066 - val_loss: 0.0126 - val_acc: 0.9247\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0145 - acc: 0.9110 - val_loss: 0.0118 - val_acc: 0.9285\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0139 - acc: 0.9143 - val_loss: 0.0112 - val_acc: 0.9298\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0136 - acc: 0.9161 - val_loss: 0.0112 - val_acc: 0.9285\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0132 - acc: 0.9175 - val_loss: 0.0111 - val_acc: 0.9322\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0132 - acc: 0.9165 - val_loss: 0.0118 - val_acc: 0.9262\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0130 - acc: 0.9176 - val_loss: 0.0106 - val_acc: 0.9312\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0126 - acc: 0.9217 - val_loss: 0.0105 - val_acc: 0.9338\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0122 - acc: 0.9242 - val_loss: 0.0102 - val_acc: 0.9385\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0124 - acc: 0.9222 - val_loss: 0.0104 - val_acc: 0.9348\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0122 - acc: 0.9238 - val_loss: 0.0107 - val_acc: 0.9325\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0119 - acc: 0.9258 - val_loss: 0.0101 - val_acc: 0.9343\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0117 - acc: 0.9275 - val_loss: 0.0100 - val_acc: 0.9377\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0116 - acc: 0.9274 - val_loss: 0.0100 - val_acc: 0.9363\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0115 - acc: 0.9275 - val_loss: 0.0096 - val_acc: 0.9417\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0112 - acc: 0.9293 - val_loss: 0.0095 - val_acc: 0.9403\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0109 - acc: 0.9312 - val_loss: 0.0091 - val_acc: 0.9438\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0109 - acc: 0.9306 - val_loss: 0.0091 - val_acc: 0.9413\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0113 - acc: 0.9280 - val_loss: 0.0093 - val_acc: 0.9412\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0109 - acc: 0.9312 - val_loss: 0.0086 - val_acc: 0.9478\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0109 - acc: 0.9309 - val_loss: 0.0095 - val_acc: 0.9415\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0108 - acc: 0.9315 - val_loss: 0.0090 - val_acc: 0.9428\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0108 - acc: 0.9310 - val_loss: 0.0095 - val_acc: 0.9407\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0106 - acc: 0.9315 - val_loss: 0.0091 - val_acc: 0.9407\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0109 - acc: 0.9305 - val_loss: 0.0088 - val_acc: 0.9443\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0105 - acc: 0.9337 - val_loss: 0.0088 - val_acc: 0.9462\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0104 - acc: 0.9341 - val_loss: 0.0085 - val_acc: 0.9448\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0105 - acc: 0.9320 - val_loss: 0.0085 - val_acc: 0.9443\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0099 - acc: 0.9369 - val_loss: 0.0084 - val_acc: 0.9455\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0103 - acc: 0.9342 - val_loss: 0.0087 - val_acc: 0.9442\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0101 - acc: 0.9353 - val_loss: 0.0088 - val_acc: 0.9447\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0098 - acc: 0.9384 - val_loss: 0.0085 - val_acc: 0.9455\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0099 - acc: 0.9367 - val_loss: 0.0079 - val_acc: 0.9492\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0093 - acc: 0.9404 - val_loss: 0.0083 - val_acc: 0.9467\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0099 - acc: 0.9367 - val_loss: 0.0099 - val_acc: 0.9353\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0101 - acc: 0.9361 - val_loss: 0.0083 - val_acc: 0.9475\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0094 - acc: 0.9396 - val_loss: 0.0080 - val_acc: 0.9495\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0097 - acc: 0.9377 - val_loss: 0.0085 - val_acc: 0.9430\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0095 - acc: 0.9389 - val_loss: 0.0081 - val_acc: 0.9482\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=100, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x189e38d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAH5BJREFUeJzt3XtwXOd53/Hvs4tdXBYgLgQo3sCLKOpCxbIVw7Qb2dbFlkrZiZTUTksl6sTTJGw6VuL60kROXNVVJk3rduJ2pupM1dQTN74wqpvYrIcdJbVJ22ksmZAtywJJyCAlEBBIYgmAWGAXwGJ3n/6xS2oFgsSSXGCxZ3+fmZ3dc/bl2eeAyx9evuc955i7IyIiwRKqdAEiIlJ+CncRkQBSuIuIBJDCXUQkgBTuIiIBpHAXEQkghbuISAAp3EVEAkjhLiISQHWV+uDOzk7ftm1bpT5eRKQqvfDCC+fcvWupdhUL923bttHb21upjxcRqUpmNlhKOw3LiIgEkMJdRCSAFO4iIgGkcBcRCSCFu4hIACncRUQCSOEuIhJAFZvnLiKykpJzGV49l+REfJrhiRm6WurZ0dXMjq4YbU3Rq97e9FyG184lmUilaWuM0h6L0BGL0hgJY2aXtM9kcyTnskynM7Q01LGmIVKO3boshbuIrJjZ+SzHz0zxk9cnGTg7RWtjhA1tjaxvbWBjayMb2hpoqa/DzHB3ZuazJOeypNIZknNZ4tNzDI2nGJ6YYWgi/zw8nmJqLkNrY4T2pghtjVFamyK0NUaI1IUYHEtyMp7k9OTsZetaG4tyY1eMGzubaYtFqA+HiNaFiBSeo3UhEjMZXj03zWvnUpw8l+Tc9Nyi26qvC9HeFKWloY7ZTL7+6bkM6UzuYpt/80tv4VfeuaXsP99iCneRMpmdzzKeTJPO5C4GQn3hORoOLdqbu5xMNsfZqTmyWSccNsJmhENvPHI5Zz6bI53Nkc7kmM/ml3PuRMIhImGjLhQiUhciEjJCISNTaDOfzZHJOelMvn19XZjGSJiGaIjGSP51OGSMJ9MMTcwwNJ5iaCLF0PgMwxMpErMZMtkc2UINmZyTyTqRsLG2uZ61sShrm+vpbI6yNhYlHDL6RhL85PVJ+s9Mkck5AM31dSTTGdzfvO+xaBiA1Hz2kvcuiISNTW2NdHc08cDt61nTUEdidp6J5DznZ9IMjad4eWae2fksWzqa+Hs3ruXGrhg7upq5sauZ7o5GRhNznIhPczKe5OS5aU6MJvnW8VESs/NvCuJiXS31bF8b475bu9je2cz2ziY6YvVMzswzkUwznkrnn5NppmYzNEbDxOrDxOrriEXriNXX0VwfpmdbR8nfhWulcJfAy+acqdl5JlLzpNIZAAzDjPyj8NodHM8/F17ncpCYned8ap6JVJrzqTQThdcX/hGPp9KMT6dJprNXrCMWDXPDmgbWtzaw/sJzawOtjRFGzs9yajzF0HiKU+MpXj8/QzZ3mWRbASGDhR+/NhZlc0cTbY0R6kJGXeEXyIXndDbH2PQcg2MpfnhqgvFk+uI2Whsj3LG5lX3vvZE7Nrfyls1tbGxtIJNzRqfmOH1+hpHJWc5MznB6cpaQGbFomKb6uvxztI5YfZiOWD3dHY3c0NJAKFT6L8vFbOusY1tnjPfddul77n7xF2D+l2eOxmiYlmUeSiknhbtUVHIuw5nELGcTs0zNZmhrjFzs/bU2Ri75BzyfzTE5M3/xMZFMM3YhZJNpxqbTjCfnmEjNcz6V5nyh3eV6gNeiKRqmrTFCR3OUjlg92ztjdMTqWdscpSMWpb4uRDqTY64QDOls/vXU7DyjiTlOT87w/KvjnE3MXuzFAnTEonR3NPHW7jZ+4a0b2NTWRCRs5NzJ5iCby/eWMzknHLI3hg2KhhAMyORypLNOJpsjk3XSRT36upAVevb5UA6bMZfJMTOfZbbwmElnmc1kWRurp7ujie6ORrrbm4jVX11cZHPO+VSauUyODa0Ni/7P5UIPfFNb4/X+tZSVmREJ539WsfpKV3NtFO6yrNzzPbNXzk7xytlpBkanGBxLcTYxy9nEHNNzmcv+2XDIaG+K0tpYRyqdZXJmntQVesf1dSHWxqJ0NEdpb4qypaOJtqYIbU1R2hojtMciNEYufOULPXTe6KVf7M2T79GDETJY0xihvSla2FaE+rpwWX42uZxzLjnHZGqe9a0NVdUrLEU4lB+mkcpQuNc4dyeZzjKRTBeGHeaZnsswNTvP1GyG6bkM07MZkuks9XUhGqP5MdmmaJiGSP6RzuQuHvBKpfN/JjmXYWhihp+enSIx+0aAtzdF2N4Z45b1LbxnZ9fFIYp1a+pZ0xDhfGqeseQcY9NpxpJzjCfTTM7M0xSto7UxcsmjPZYf1+2IRWmKLj5LYbUKhYx1LQ2sa2modCkSQAr3gEvOZTg1nmJwLD+eOzieZHAsxWhijvHCGPJ89spjFrFomMZomLlMjtn57BXbN0RCxKJ1NEbDbGxt5BfeupGbb2hh57pmdt7QQmdztKoCWKRalRTuZrYH+E9AGPhTd/+3C97fCnwB6ALGgUfdfbjMtcoVzGdznIhPc/z0FMfOJDh+eorjZxKcTbx5ulZrY4QtHU1sXdvEnVvaaGuK0hHLD110NOWnkLU01NHSEKG5vo7m+jrCi4x7Xxybnc/PDInV5w96LWwrIpWxZLibWRh4CrgfGAaOmNkBdz9a1Ow/AP/D3b9oZvcBfwz84+UouNa5O/HpuYvhnQ/zKQZGpy72qKPhEDeta+auHZ3sWNd8Mcy3dsRobbr+cd0LB+SCNkYsEiSl9Nx3AwPufhLAzPYDDwPF4b4L+Hjh9SHg6+UsslZlc86r56bpG0nw8uuTHD2dD/OxZPpimw2tDdyyvoV7buni1vUt3LZhDds7Y0TCurKESC0rJdw3AUNFy8PAOxe0+THwIfJDN78EtJjZWncfK0uVNWI0Mcv3T47R+9oEfSOTHDs9xcx8fnZItC7ELTe08L7b1nHbhjXcun4Nt65voT129adNi0jwlRLuiw2iLjyi9ingP5vZR4DvAq8Dl8xxM7N9wD6ALVuW99TbanA+lea5k2P83Yn8Y2B0Gsifubdrwxr27u7m9o2t3L5xDTeta1ZvXERKVkq4DwPdRcubgZHiBu4+AvwDADNrBj7k7pMLN+TuTwNPA/T09FTu9LsKmpyZ55svjfCXP3ydH56awB0aI2F2b+/gl9++mZ/b0cmujWt0YFJErksp4X4E2Glm28n3yPcCv1LcwMw6gXF3zwGfJj9zRgqyOedvB87xtReGebbvDOlMjp3rmvnY+3by7ps6uWNzG9E69cpFpHyWDHd3z5jZY8Cz5KdCfsHd+8zsSaDX3Q8A9wB/bGZOfljmo8tYc9XI5ZynDg3wpecHOZuYo7Uxwt53dPPht2/mLZtaNd9bRJaNeTkvunEVenp6vLe3tyKfvRJyOef3/+on7D8yxN03d7H3Hd3cd9u6sp26LiK1ycxecPeepdrpDNVlkMs5f/D1fLD/9n038Yn7b1YvXURWlAZ6yyyXcz7zjZf56g+G+Oi9OxTsIlIRCvcycnf+5Tde5ivPn+Kf3bODTz1wi4JdRCpC4V4m7s4T3+jjy8+f4rfu3sHv/n0Fu4hUjsK9DNydzx7o48+fG+SfvvdGfm+Pgl1EKkvhXga9gxN88fuD/JO7tvP4g7cq2EWk4hTuZfDt46PUhYyP379TwS4iq4LCvQwO98d5+9Z2XQJXRFYNhft1OpuY5djpBHff0lXpUkRELlK4X6fv9McBuOfmdRWuRETkDQr363T4lVFuWFPPbRtaKl2KiMhFCvfrkMnm+N5Pz3H3zV06kCoiq4rC/Tr88NR5pmYz3HOLhmREZHVRuF+Hw/2jhEPGXTd1VroUEZE3Ubhfh8P9cd6+pZ3WRk2BFJHVReF+jUYTsxzVFEgRWaUU7tfo8CuFKZAKdxFZhUoKdzPbY2b9ZjZgZo8v8v4WMztkZj8ys5fM7APlL3V1+U5/nHUt9ezasKbSpYiIXGLJcDezMPAU8CCwC3jEzHYtaPYZ4Bl3v5P8DbT/S7kLXU3yUyDjmgIpIqtWKT333cCAu5909zSwH3h4QRsHLnRhW4GR8pW4+rw4dJ6EpkCKyCpWSrhvAoaKlocL64p9FnjUzIaBg8BvL7YhM9tnZr1m1huPx6+h3NXhcH+ccMh4905NgRSR1amUcF9s3MEXLD8C/Jm7bwY+APy5mV2ybXd/2t173L2nq6t6D0QefmWUn93SpimQIrJqlRLuw0B30fJmLh12+XXgGQB3/z7QAASyWzs6NcvLryc0JCMiq1op4X4E2Glm280sSv6A6YEFbU4B7wMws9vIh3v1jrtcwXdfOQfA3TdX7/88RCT4lgx3d88AjwHPAsfIz4rpM7MnzeyhQrNPAr9pZj8Gvgp8xN0XDt0EwuH+Ubpa6rl9o6ZAisjqVVdKI3c/SP5AafG6J4peHwXuKm9pq8+Fq0Dev+sGTYEUkVVNZ6hehR8Pn2dyZl5DMiKy6incr8Lzr44D8G5dBVJEVjmF+1XoG0mwub2R9li00qWIiFyRwv0qHBtJ6FoyIlIVFO4lSs5leHUsye0bWytdiojIkhTuJTp+JoE7mgIpIlVB4V6ivpEEALsU7iJSBRTuJep7PUF7U4QNrQ2VLkVEZEkK9xIdPZ1g18Y1OnlJRKqCwr0E89kc/WemdDBVRKqGwr0EJ+LTpLM5HUwVkaqhcC9B3+uFg6ma4y4iVULhXoKjpxM0RELc2NVc6VJEREqicC9B38gkt65fQzikg6kiUh0U7ktwd46OJDS/XUSqisJ9CcMTMyRmMzqYKiJVpaRwN7M9ZtZvZgNm9vgi73/ezF4sPF4xs/PlL7UyLp6ZqoOpIlJFlrwTk5mFgaeA+8nfLPuImR0o3H0JAHf/eFH73wbuXIZaK+Lo6QQhg1vXK9xFpHqU0nPfDQy4+0l3TwP7gYev0P4R8vdRDYSjI5Ps6GqmMRqudCkiIiUrJdw3AUNFy8OFdZcws63AduDb11/a6tCng6kiUoVKCffF5v/5ZdruBb7m7tlFN2S2z8x6zaw3Ho+XWmPFjCfTnJ6c1cFUEak6pYT7MNBdtLwZGLlM271cYUjG3Z929x537+nqWv03mT568WCqrikjItWllHA/Auw0s+1mFiUf4AcWNjKzW4B24PvlLbFyjp6eBHSDDhGpPkuGu7tngMeAZ4FjwDPu3mdmT5rZQ0VNHwH2u/vlhmyqTt9Igo2tDbohtohUnSWnQgK4+0Hg4IJ1TyxY/mz5yloddDBVRKqVzlC9jJl0lpPxaXbpGu4iUoUU7pdx/EyCnG6ILSJVSuF+GUdP67IDIlK9FO6X0TeSYE1DHZvbGytdiojIVVO4X8aFg6m6IbaIVCOF+yIy2RzHTyd0Q2wRqVoK90W8ei7JXEY3xBaR6qVwX8TFg6kKdxGpUgr3RfSNJIjWhdihG2KLSJVSuC/iZHyaGztjRML68YhIdVJ6LeLUeIotHU2VLkNE5Jop3Bdwd4W7iFQ9hfsC8ak5ZudzbF2rcBeR6qVwX+DUeAqAbvXcRaSKKdwXGBzLh7uGZUSkmincFzg1nsIMNrcr3EWkeincFxgaT7GxtZFonX40IlK9SkowM9tjZv1mNmBmj1+mzT80s6Nm1mdmXylvmStncDxFd4euBCki1W3J2+yZWRh4CrgfGAaOmNkBdz9a1GYn8GngLnefMLN1y1Xwcjs1nuK+W6q2fBERoLSe+25gwN1Punsa2A88vKDNbwJPufsEgLuPlrfMlZFKZ4hPzbFF0yBFpMqVEu6bgKGi5eHCumI3Azeb2f8zs+fMbE+5ClxJQ+MzgGbKiEj1W3JYBljsbhW+yHZ2AvcAm4HvmdnPuPv5N23IbB+wD2DLli1XXexyuzDHXeEuItWulJ77MNBdtLwZGFmkzTfcfd7dXwX6yYf9m7j70+7e4+49XV1d11rzshkcSwIKdxGpfqWE+xFgp5ltN7MosBc4sKDN14F7Acysk/wwzclyFroShsZTtDTU0dYUqXQpIiLXZclwd/cM8BjwLHAMeMbd+8zsSTN7qNDsWWDMzI4Ch4B/4e5jy1X0crlwwTDdN1VEql0pY+64+0Hg4IJ1TxS9duAThUfVGhxPcev6lkqXISJy3XQaZkEu5wyPz+iCYSISCAr3gjOJWdLZnA6mikggKNwLLkyD3NoRq3AlIiLXT+FeoDnuIhIkCveCU2MpwiFjQ1tDpUsREbluCveCU+MpNrU1EgnrRyIi1U9JVqCbYotIkCjcC06Np3Q1SBEJDIU7MDU7z3gyrZ67iASGwh3NlBGR4FG4k79gGCjcRSQ4FO4U9dw15i4iAaFwBwbHUrQ3RVjToEv9ikgwKNzRNEgRCR6FO/kxd10NUkSCpObDPZPNMTwxw1aNt4tIgNR8uJ+enCWTcw3LiEiglBTuZrbHzPrNbMDMHl/k/Y+YWdzMXiw8fqP8pS6PN6ZB6lK/IhIcS95mz8zCwFPA/cAwcMTMDrj70QVN/8LdH1uGGpfVoKZBikgAldJz3w0MuPtJd08D+4GHl7eslXNqPEUkbKxfo0v9ikhwlBLum4ChouXhwrqFPmRmL5nZ18ysuyzVrYBTYym625sIh6zSpYiIlE0p4b5Y6vmC5f8NbHP3O4D/C3xx0Q2Z7TOzXjPrjcfjV1fpMjmlaZAiEkClhPswUNwT3wyMFDdw9zF3nyss/jfg7YttyN2fdvced+/p6uq6lnrLTicwiUgQlRLuR4CdZrbdzKLAXuBAcQMz21C0+BBwrHwlLp/J1DyTM/Oa4y4igbPkbBl3z5jZY8CzQBj4grv3mdmTQK+7HwB+x8weAjLAOPCRZay5bC5cMEzDMiISNEuGO4C7HwQOLlj3RNHrTwOfLm9py+9CuKvnLiJBU9NnqA6OJwHoble4i0iw1HS4D42n6GyOEqsv6T8wIiJVo6bDfXBMM2VEJJhqOtxfO5dk61pdU0ZEgqdmwz05l2Fkcpab1jVXuhQRkbKr2XA/Gc8fTN3RpXAXkeCp2XAfiE8BcNM6DcuISPDUbriPTlMXMo25i0gg1XS4b13bRCRcsz8CEQmwmk22E/GkDqaKSGDVZLjPZ3O8di6pg6kiElg1Ge6DYykyOVfPXUQCqybDfWB0GkDhLiKBVZPhfiKeD3cNy4hIUNVmuI9Os6G1QRcME5HAqslwH4hPa0hGRAKt5sLd3TkxOq0hGREJtJLC3cz2mFm/mQ2Y2eNXaPdhM3Mz6ylfieV1enKWZDqrnruIBNqS4W5mYeAp4EFgF/CIme1apF0L8DvA8+Uuspx0MFVEakEpPffdwIC7n3T3NLAfeHiRdn8IfA6YLWN9ZadpkCJSC0oJ903AUNHycGHdRWZ2J9Dt7t+80obMbJ+Z9ZpZbzwev+piy2FgdJrWxgidzdGKfL6IyEooJdxtkXV+8U2zEPB54JNLbcjdn3b3Hnfv6erqKr3KMhoYzc+UMVtst0REgqGUcB8GuouWNwMjRcstwM8Ah83sNeBdwIHVelD1RHyaHV26zK+IBFsp4X4E2Glm280sCuwFDlx4090n3b3T3be5+zbgOeAhd+9dloqvw/lUmnPTaY23i0jgLRnu7p4BHgOeBY4Bz7h7n5k9aWYPLXeB5XRhpozCXUSCrqTz7939IHBwwbonLtP2nusva3lcnCnT1VLhSkRElldNnaE6MDpNtC7EpvbGSpciIrKsaircT8ST3NgZIxzSTBkRCbaaCvcL0yBFRIKuZsJ9dj7L0ERK4S4iNaFmwv1kPIm7rikjIrWhZsJ9QNMgRaSG1Ey4nxidJmSwvVNnp4pI8NVMuA/Ep+nuaKIhEq50KSIiy65mwl13XxKRWlIT4Z7NOSfPJTXeLiI1oybCfXgiRTqT4yb13EWkRtREuF+4pswO9dxFpEbUVLir5y4itaJmwr2zuZ7WpkilSxERWRG1Ee7xaW5ap/ntIlI7Ah/u7s4JXTBMRGpMSeFuZnvMrN/MBszs8UXe/y0z+4mZvWhmf2tmu8pf6rX50dB5ErMZ3rKptdKliIismCXD3czCwFPAg8Au4JFFwvsr7v4Wd38b8DngT8pe6TX60nODxKJhPnjHxkqXIiKyYkrpue8GBtz9pLungf3Aw8UN3D1RtBgDvHwlXrvzqTTffOk0v/Szm2iuL+mOgiIigVBK4m0ChoqWh4F3LmxkZh8FPgFEgfvKUt11+toLw6QzOX71nVsrXYqIyIoqpee+2D3pLumZu/tT7r4D+D3gM4tuyGyfmfWaWW88Hr+6Sq9SLud8+flTvH1rO7dtWLOsnyUistqUEu7DQHfR8mZg5Art9wO/uNgb7v60u/e4e09XV1fpVV6Dvzsxxqvnkjz6ri3L+jkiIqtRKeF+BNhpZtvNLArsBQ4UNzCznUWLHwR+Wr4Sr82Xnx+kvSnCgz+zodKliIisuCXH3N09Y2aPAc8CYeAL7t5nZk8Cve5+AHjMzN4PzAMTwK8tZ9FLOZuY5a+PnuU33r1d128XkZpU0hQSdz8IHFyw7omi1x8rc13XZf8PhsjmnEd2a0hGRGpT4M5QzWRzfPUHp3jPzk626ZZ6IlKjAhfu3z4+ypnELI++S9MfRaR2BS7cv/T8KTa0NvC+W9dVuhQRkYoJVLgPjiX57itx9r5jC3XhQO2aiMhVCVQCfuX5U4RDxj96R/fSjUVEAiww4T6XyfJM7xD333YD61sbKl2OiEhFBSbcD/fHmUjN88g7Nf1RRCRA4T5Kc30dP7djbaVLERGpuECEu7tz6Hic9+zsJKIDqSIiwQj3/rNTnEnMcu8tmv4oIgIBCfdDx/OXD777luW90qSISLUIRrj3j7JrwxpuWKNZMiIiEIBwn5yZ54XBCe69Vb12EZELqj7c//an58jmXOPtIiJFqj7cD/WP0toY4W3dbZUuRURk1ajqcM/lnMP9cd57c5euJSMiUqSqE/Ho6QTnpue4V7NkRETepKRwN7M9ZtZvZgNm9vgi73/CzI6a2Utm9i0zW5GLqR86PooZvPdmhbuISLElw93MwsBTwIPALuARM9u1oNmPgB53vwP4GvC5che6mEP9o9yxqZXO5vqV+DgRkapRSs99NzDg7ifdPQ3sBx4ubuDuh9w9VVh8Dthc3jIvNZ5M86Oh89yjWTIiIpcoJdw3AUNFy8OFdZfz68D/uZ6iSvG9n8Zxh3t1xyURkUvUldDGFlnnizY0exToAe6+zPv7gH0AW7Zc36V5Dx0fZW0syh2bWq9rOyIiQVRKz30YKL610WZgZGEjM3s/8AfAQ+4+t9iG3P1pd+9x956urms/CJrNOd95Jc7dN3cRCi32u0dEpLaVEu5HgJ1mtt3MosBe4EBxAzO7E/iv5IN9tPxlvtlLw+eZSM1zj4ZkREQWtWS4u3sGeAx4FjgGPOPufWb2pJk9VGj274Fm4H+a2YtmduAymyuLQ/1xQgbv3dm5nB8jIlK1Shlzx90PAgcXrHui6PX7y1zXFR3uH+XOLe20NUVX8mNFRKpG1Z2hGp+a46XhSZ2VKiJyBVUX7t95JX9jDs1vFxG5vKoL9zUNdTyw6wZu37im0qWIiKxaJY25ryYP3L6eB25fX+kyRERWtarruYuIyNIU7iIiAaRwFxEJIIW7iEgAKdxFRAJI4S4iEkAKdxGRAFK4i4gEkLkvet+N5f9gszgweI1/vBM4V8ZyqkWt7jfU7r5rv2tLKfu91d2XvLhWxcL9ephZr7v3VLqOlVar+w21u+/a79pSzv3WsIyISAAp3EVEAqhaw/3pShdQIbW631C7+679ri1l2++qHHMXEZErq9aeu4iIXEHVhbuZ7TGzfjMbMLPHK13PcjGzL5jZqJm9XLSuw8z+xsx+Wnhur2SNy8HMus3skJkdM7M+M/tYYX2g993MGszsB2b248J+/+vC+u1m9nxhv//CzAJ542AzC5vZj8zsm4XlwO+3mb1mZj8xsxfNrLewrmzf86oKdzMLA08BDwK7gEfMbFdlq1o2fwbsWbDuceBb7r4T+FZhOWgywCfd/TbgXcBHC3/HQd/3OeA+d38r8DZgj5m9C/h3wOcL+z0B/HoFa1xOHwOOFS3Xyn7f6+5vK5r+WLbveVWFO7AbGHD3k+6eBvYDD1e4pmXh7t8Fxhesfhj4YuH1F4FfXNGiVoC7n3b3HxZeT5H/B7+JgO+7500XFiOFhwP3AV8rrA/cfgOY2Wbgg8CfFpaNGtjvyyjb97zawn0TMFS0PFxYVytucPfTkA9BINB3CTezbcCdwPPUwL4XhiZeBEaBvwFOAOfdPVNoEtTv+38EfhfIFZbXUhv77cBfm9kLZravsK5s3/Nqu4eqLbJO030CyMyagf8F/HN3T+Q7c8Hm7lngbWbWBvwVcNtizVa2quVlZj8PjLr7C2Z2z4XVizQN1H4X3OXuI2a2DvgbMztezo1XW899GOguWt4MjFSolko4a2YbAArPoxWuZ1mYWYR8sH/Z3f+ysLom9h3A3c8Dh8kfc2gzswudsCB+3+8CHjKz18gPs95Hvicf9P3G3UcKz6Pkf5nvpozf82oL9yPAzsKR9CiwFzhQ4ZpW0gHg1wqvfw34RgVrWRaF8db/Dhxz9z8peivQ+25mXYUeO2bWCLyf/PGGQ8CHC80Ct9/u/ml33+zu28j/e/62u/8qAd9vM4uZWcuF18ADwMuU8XtedScxmdkHyP9mDwNfcPc/qnBJy8LMvgrcQ/4qcWeBfwV8HXgG2AKcAn7Z3RcedK1qZvZu4HvAT3hjDPb3yY+7B3bfzewO8gfQwuQ7Xc+4+5NmdiP5Hm0H8CPgUXefq1yly6cwLPMpd//5oO93Yf/+qrBYB3zF3f/IzNZSpu951YW7iIgsrdqGZUREpAQKdxGRAFK4i4gEkMJdRCSAFO4iIgGkcBcRCSCFu4hIACncRUQC6P8DetD0Zc4H3LQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      5923\n",
      "          1       0.97      0.98      0.97      6742\n",
      "          2       0.95      0.93      0.94      5958\n",
      "          3       0.92      0.93      0.93      6131\n",
      "          4       0.94      0.94      0.94      5842\n",
      "          5       0.93      0.91      0.92      5421\n",
      "          6       0.95      0.97      0.96      5918\n",
      "          7       0.95      0.95      0.95      6265\n",
      "          8       0.94      0.92      0.93      5851\n",
      "          9       0.91      0.93      0.92      5949\n",
      "\n",
      "avg / total       0.94      0.94      0.94     60000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9429166666666666"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用classification_report可以看看每個數字的精確度(非準確率)\n",
    "\n",
    "print(\"Train data：\")\n",
    "print(classification_report(y_train.argmax(1), model.predict(x_train).argmax(1)))\n",
    "metrics.accuracy_score(y_train.argmax(1), model.predict(x_train).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.97      0.98      0.98      1135\n",
      "          2       0.95      0.92      0.94      1032\n",
      "          3       0.92      0.94      0.93      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.92      0.90      0.91       892\n",
      "          6       0.94      0.96      0.95       958\n",
      "          7       0.95      0.94      0.94      1028\n",
      "          8       0.94      0.92      0.93       974\n",
      "          9       0.92      0.92      0.92      1009\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9396"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test data：\")\n",
    "print(classification_report(y_test.argmax(1), model.predict(x_test).argmax(1)))\n",
    "metrics.accuracy_score(y_test.argmax(1), model.predict(x_test).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_0</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>predict_3</th>\n",
       "      <th>predict_4</th>\n",
       "      <th>predict_5</th>\n",
       "      <th>predict_6</th>\n",
       "      <th>predict_7</th>\n",
       "      <th>predict_8</th>\n",
       "      <th>predict_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>5789</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>1</td>\n",
       "      <td>6586</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_2</th>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>5520</td>\n",
       "      <td>85</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_3</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>5683</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_4</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>5466</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_5</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>132</td>\n",
       "      <td>41</td>\n",
       "      <td>4936</td>\n",
       "      <td>66</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_6</th>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "      <td>5751</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_7</th>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5946</td>\n",
       "      <td>8</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_8</th>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>5370</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_9</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>109</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>47</td>\n",
       "      <td>5528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predict_0  predict_1  predict_2  predict_3  predict_4  predict_5  \\\n",
       "true_0       5789          0          9          8          8         27   \n",
       "true_1          1       6586         30         37         10          3   \n",
       "true_2         34         46       5520         85         53          9   \n",
       "true_3         31         13        100       5683          5        109   \n",
       "true_4          7         22         20          6       5466          1   \n",
       "true_5         75          6         22        132         41       4936   \n",
       "true_6         36         16         14          0         29         53   \n",
       "true_7         10         39         44         38         41         14   \n",
       "true_8         17         55         44         96         31         79   \n",
       "true_9         22         18          9         67        109         54   \n",
       "\n",
       "        predict_6  predict_7  predict_8  predict_9  \n",
       "true_0         37         17         19          9  \n",
       "true_1          5         12         43         15  \n",
       "true_2         59         80         56         16  \n",
       "true_3         14         54         72         50  \n",
       "true_4         83         13         18        206  \n",
       "true_5         66         21         88         34  \n",
       "true_6       5751          1         17          1  \n",
       "true_7          3       5946          8        122  \n",
       "true_8         54         13       5370         92  \n",
       "true_9          3         92         47       5528  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion_matrix可以看出每個預測錯誤的是預測成哪一個\n",
    "CMtrain = confusion_matrix(y_train.argmax(1), model.predict(x_train).argmax(1))\n",
    "CMtrain = pd.DataFrame(CMtrain,index = [\"true_0\",\"true_1\",\"true_2\",\"true_3\",\"true_4\",\"true_5\",\"true_6\",\"true_7\",\"true_8\",\"true_9\"],\n",
    "                     columns = [\"predict_0\",\"predict_1\",\"predict_2\",\"predict_3\",\"predict_4\",\"predict_5\",\"predict_6\",\"predict_7\",\"predict_8\",\"predict_9\"])\n",
    "CMtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_0</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>predict_3</th>\n",
       "      <th>predict_4</th>\n",
       "      <th>predict_5</th>\n",
       "      <th>predict_6</th>\n",
       "      <th>predict_7</th>\n",
       "      <th>predict_8</th>\n",
       "      <th>predict_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1114</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>950</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>949</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_5</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>802</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_6</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>917</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_8</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_9</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predict_0  predict_1  predict_2  predict_3  predict_4  predict_5  \\\n",
       "true_0        958          0          2          2          1          4   \n",
       "true_1          0       1114          3          2          0          1   \n",
       "true_2         15          4        950         18          8          0   \n",
       "true_3          2          1         11        949          0         20   \n",
       "true_4          2          3          3          1        915          1   \n",
       "true_5         10          1          1         35          5        802   \n",
       "true_6          9          3          5          0          9         11   \n",
       "true_7          1         10         19          7          7          0   \n",
       "true_8          5          5          4         13         11         17   \n",
       "true_9          6          6          1          7         26         14   \n",
       "\n",
       "        predict_6  predict_7  predict_8  predict_9  \n",
       "true_0          9          3          1          0  \n",
       "true_1          4          3          7          1  \n",
       "true_2         15         13          4          5  \n",
       "true_3          1         10         11          5  \n",
       "true_4         14          1          2         40  \n",
       "true_5          8          7         19          4  \n",
       "true_6        917          2          2          0  \n",
       "true_7          0        963          0         21  \n",
       "true_8          9          4        896         10  \n",
       "true_9          1          9          7        932  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMtest = confusion_matrix(y_test.argmax(1), model.predict(x_test).argmax(1))\n",
    "CMtest = pd.DataFrame(CMtest,index = [\"true_0\",\"true_1\",\"true_2\",\"true_3\",\"true_4\",\"true_5\",\"true_6\",\"true_7\",\"true_8\",\"true_9\"],\n",
    "                     columns = [\"predict_0\",\"predict_1\",\"predict_2\",\"predict_3\",\"predict_4\",\"predict_5\",\"predict_6\",\"predict_7\",\"predict_8\",\"predict_9\"])\n",
    "CMtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將loss function換成適合多分類問題的cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Dense(100,input_dim = 784))\n",
    "model2.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Dense(500))\n",
    "model2.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Dense(250))\n",
    "model2.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.03),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2510      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 256,760\n",
      "Trainable params: 256,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 2.1999 - acc: 0.2912 - val_loss: 2.0028 - val_acc: 0.4667\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 1.5865 - acc: 0.6076 - val_loss: 1.1500 - val_acc: 0.7428\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.9360 - acc: 0.7748 - val_loss: 0.6941 - val_acc: 0.8512\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.6335 - acc: 0.8461 - val_loss: 0.4891 - val_acc: 0.8880\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.4935 - acc: 0.8748 - val_loss: 0.4127 - val_acc: 0.9010\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.4361 - acc: 0.8866 - val_loss: 0.3529 - val_acc: 0.9112\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.3909 - acc: 0.8935 - val_loss: 0.3428 - val_acc: 0.9110\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.3706 - acc: 0.8988 - val_loss: 0.3126 - val_acc: 0.9212\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.3537 - acc: 0.9013 - val_loss: 0.2947 - val_acc: 0.9222\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.3359 - acc: 0.9073 - val_loss: 0.2800 - val_acc: 0.9272\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.3145 - acc: 0.9127 - val_loss: 0.2740 - val_acc: 0.9240\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.3138 - acc: 0.9117 - val_loss: 0.2639 - val_acc: 0.9302\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2972 - acc: 0.9166 - val_loss: 0.2587 - val_acc: 0.9297\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.3000 - acc: 0.9144 - val_loss: 0.2432 - val_acc: 0.9323\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2843 - acc: 0.9186 - val_loss: 0.2393 - val_acc: 0.9352\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2859 - acc: 0.9188 - val_loss: 0.2344 - val_acc: 0.9355\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2804 - acc: 0.9187 - val_loss: 0.2646 - val_acc: 0.9235\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2716 - acc: 0.9223 - val_loss: 0.2376 - val_acc: 0.9313\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2673 - acc: 0.9227 - val_loss: 0.2196 - val_acc: 0.9423\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2562 - acc: 0.9258 - val_loss: 0.2120 - val_acc: 0.9425\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2543 - acc: 0.9269 - val_loss: 0.2194 - val_acc: 0.9347\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.2581 - acc: 0.9237 - val_loss: 0.2337 - val_acc: 0.9312\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2582 - acc: 0.9235 - val_loss: 0.2136 - val_acc: 0.9395\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2466 - acc: 0.9276 - val_loss: 0.2204 - val_acc: 0.9342\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2490 - acc: 0.9268 - val_loss: 0.2045 - val_acc: 0.9437\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2322 - acc: 0.9319 - val_loss: 0.2030 - val_acc: 0.9430\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2299 - acc: 0.9328 - val_loss: 0.2072 - val_acc: 0.9422\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2327 - acc: 0.9322 - val_loss: 0.1926 - val_acc: 0.9465\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2279 - acc: 0.9337 - val_loss: 0.2077 - val_acc: 0.9423\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.2301 - acc: 0.9336 - val_loss: 0.1999 - val_acc: 0.9442\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.2341 - acc: 0.9319 - val_loss: 0.2132 - val_acc: 0.9398\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2423 - acc: 0.9274 - val_loss: 0.2047 - val_acc: 0.9410\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2342 - acc: 0.9310 - val_loss: 0.1960 - val_acc: 0.9397\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.2255 - acc: 0.9337 - val_loss: 0.1908 - val_acc: 0.9465\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.2211 - acc: 0.9344 - val_loss: 0.1975 - val_acc: 0.9388\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.2194 - acc: 0.9348 - val_loss: 0.1972 - val_acc: 0.9423\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.2179 - acc: 0.9349 - val_loss: 0.1815 - val_acc: 0.9493\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.2152 - acc: 0.9360 - val_loss: 0.1975 - val_acc: 0.9400\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.2066 - acc: 0.9378 - val_loss: 0.1922 - val_acc: 0.9417\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2072 - acc: 0.9374 - val_loss: 0.1923 - val_acc: 0.9443\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2117 - acc: 0.9369 - val_loss: 0.1726 - val_acc: 0.9503\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2031 - acc: 0.9386 - val_loss: 0.1786 - val_acc: 0.9463\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.2012 - acc: 0.9390 - val_loss: 0.1951 - val_acc: 0.9413\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.2005 - acc: 0.9398 - val_loss: 0.1724 - val_acc: 0.9495\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.2023 - acc: 0.9387 - val_loss: 0.1855 - val_acc: 0.9458\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.2143 - acc: 0.9344 - val_loss: 0.1818 - val_acc: 0.9493\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.1956 - acc: 0.9416 - val_loss: 0.1838 - val_acc: 0.9477\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.2078 - acc: 0.9371 - val_loss: 0.1961 - val_acc: 0.9433\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.1986 - acc: 0.9398 - val_loss: 0.1722 - val_acc: 0.9508\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.2056 - acc: 0.9378 - val_loss: 0.1885 - val_acc: 0.9455\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train, batch_size=100, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c8f1940>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將優化器換成神經網路界鼎鼎大名的relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Dense(100,input_dim = 784))\n",
    "model3.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Dense(500))\n",
    "model3.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Dense(250))\n",
    "model3.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.005),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                2510      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 256,760\n",
      "Trainable params: 256,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s 43us/step - loss: 8.8050 - acc: 0.4440 - val_loss: 5.3733 - val_acc: 0.6470\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 1.9736 - acc: 0.8385 - val_loss: 0.3239 - val_acc: 0.9303\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.2875 - acc: 0.9334 - val_loss: 0.2008 - val_acc: 0.9492\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.1637 - acc: 0.9551 - val_loss: 0.1768 - val_acc: 0.9555\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.1140 - acc: 0.9674 - val_loss: 0.1531 - val_acc: 0.9612\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0831 - acc: 0.9759 - val_loss: 0.1467 - val_acc: 0.9600\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0618 - acc: 0.9827 - val_loss: 0.1472 - val_acc: 0.9632\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0469 - acc: 0.9875 - val_loss: 0.1451 - val_acc: 0.9655\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0368 - acc: 0.9909 - val_loss: 0.1496 - val_acc: 0.9652\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0292 - acc: 0.9936 - val_loss: 0.1506 - val_acc: 0.9648\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0237 - acc: 0.9954 - val_loss: 0.1499 - val_acc: 0.9660\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0198 - acc: 0.9968 - val_loss: 0.1546 - val_acc: 0.9678\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0165 - acc: 0.9977 - val_loss: 0.1544 - val_acc: 0.9655\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 39us/step - loss: 0.0141 - acc: 0.9984 - val_loss: 0.1528 - val_acc: 0.9673\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0124 - acc: 0.9989 - val_loss: 0.1588 - val_acc: 0.9663\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0112 - acc: 0.9991 - val_loss: 0.1562 - val_acc: 0.9670\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0102 - acc: 0.9993 - val_loss: 0.1567 - val_acc: 0.9687\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.1580 - val_acc: 0.9673\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.1612 - val_acc: 0.9678\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0084 - acc: 0.9995 - val_loss: 0.1638 - val_acc: 0.9683\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0080 - acc: 0.9996 - val_loss: 0.1636 - val_acc: 0.9677\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0077 - acc: 0.9996 - val_loss: 0.1645 - val_acc: 0.9680\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0075 - acc: 0.9996 - val_loss: 0.1642 - val_acc: 0.9687\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0073 - acc: 0.9996 - val_loss: 0.1649 - val_acc: 0.9682\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0072 - acc: 0.9996 - val_loss: 0.1659 - val_acc: 0.9685\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0071 - acc: 0.9996 - val_loss: 0.1660 - val_acc: 0.9687\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.1670 - val_acc: 0.9685\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 0.1682 - val_acc: 0.9688\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0067 - acc: 0.9996 - val_loss: 0.1678 - val_acc: 0.9688\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0067 - acc: 0.9996 - val_loss: 0.1692 - val_acc: 0.9690\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0066 - acc: 0.9996 - val_loss: 0.1687 - val_acc: 0.9687\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.1695 - val_acc: 0.9687\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.1695 - val_acc: 0.9693\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0064 - acc: 0.9996 - val_loss: 0.1700 - val_acc: 0.9692\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.1708 - val_acc: 0.9690\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.1708 - val_acc: 0.9692\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.1711 - val_acc: 0.9688\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.1716 - val_acc: 0.9692\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.1719 - val_acc: 0.9693\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0062 - acc: 0.9997 - val_loss: 0.1716 - val_acc: 0.9692\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.1723 - val_acc: 0.9693\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.1726 - val_acc: 0.9688\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.1730 - val_acc: 0.9690\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0061 - acc: 0.9997 - val_loss: 0.1728 - val_acc: 0.9687\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.1729 - val_acc: 0.9692\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.1736 - val_acc: 0.9688\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.1734 - val_acc: 0.9692\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 38us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.1739 - val_acc: 0.9690\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.1737 - val_acc: 0.9692\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.1746 - val_acc: 0.9690\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train, y_train, batch_size=100, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e433128>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFspJREFUeJzt3X+Q3PV93/Hn++50J+kECKGzBPqBgAqCSG2wZZrEqU2c4MiuB5wmriHNTNxJg5uYNLWdZKBpSUrjdjqT1J04NBmaMnY8jjGDY6xmNENcg5O09Q+JALYlVSCrxjpLwCEEh+5Ot3d77/6xe7A67d2tYE/L97vPx8zN7ve7n919f8arFx+/97vfb2QmkqRy6el0AZKk9jPcJamEDHdJKiHDXZJKyHCXpBIy3CWphAx3SSohw12SSshwl6QS6uvUG69duza3bNnSqbeXpEJ65JFHnsvMocXGdSzct2zZwp49ezr19pJUSBHxVCvjbMtIUgkZ7pJUQoa7JJWQ4S5JJbRouEfEPRHxbER8Z57HIyL+MCIORsS3IuLN7S9TknQmWlm5fwrYscDj7wa21v9uAf74tZclSXotFg33zPwb4PkFhtwI/FnWfB1YHREXtqtASdKZa8dx7huAww3bw/V9R9vw2mqzzOTk1Awnp6pUqjNMTs1QqVaZnJ6hMj3DVDWpziSZSTVr92cyqc5Adaa2PT0zw0wm09VXHpvJ2nNmkpefU3s/SLJ+u1htr4xtrPeU7QWeH/O97pz3OBPZ8OwiX5HylNKLPJGS+Mkr1/GmTauX9D3aEe7N/k01/fRExC3UWjds3ry5DW/dXaaqMxwfr3B8bIpjY5McH5vi+fEKx8cqnJicZqz+d2Kyynildn+8UmW8UuXkVO12Yqra6WnodSDm+y+hzoo3nLu8EOE+DGxq2N4IHGk2MDPvBu4G2L59u8uHBpnJcycqHBo5wVPPj/PMiyc5OnqSZ148ydOjJ3n6xZMcG6vM+/yBvh4GB/oYHOhlsL+PVQN9nLeyn4tW97Kiv5cVy3pZWb9d0d/H8mU99Pf10N9bux3o62Ggr5e+3qC3J+iNoKcn6IlXtnt7Xvnrq9/2zI4NXh7fExD1W6jdD2qBEvOur2fHzrkl6s9rHHP6azRe6D05fcXR+JwzzbXGt2v23tLrUTvCfSdwa0TcC/wD4MXMtCUzj8zk6Isn2XtklCeeeYlDI2N8d+QEh0ZOMHpy+pSxawb7WXfuci48bzlv3LiadecOcMGqAdas7Of8wWWsGexnzcp+Vq/sp7+v249qNXSlRouGe0R8DrgOWBsRw8DvAMsAMvNPgF3Ae4CDwDjwz5aq2KLJTJ46Ns7jwy+w78goe4+MsvfIixwfn3p5zPpzl3Pp0CA3XH0Rlw2t4tKhVWy5YCXrzl3O8mW9HaxeUpEtGu6ZefMijyfw4bZVVHAvTkzxte8+x18/8Rx/++QIw8cnAOjv7eGK9efw01et56qLzmXbRedxxfpzWDXQsXO3SSoxk6UNDj8/zgOP/oCvPjHCY4dfoDqTrBro40cvu4APvf1S3nLxGrauW8Wy3m5vnUg6Wwz3V2lyusqX9z3Dvd88zP86+BwR8MYN5/Er77iMt18+xDWbVxvmkjrGcD9DTz7zEp/ffZi/ePQHPD9WYcPqFXzkpy7n/ds3ctHqFZ0uT5IAw71le773PJ986CB//cQIy3qD67et4wNv3cyP/7219PZ4pIak1xfDfQGZyf/57jE++dCTfP3Q81ww2M9v/vQVfOCtm1i7aqDT5UnSvAz3JjKThw88yycfOsij33+BdecO8G/fu42fv3YzK/o9PFHS65/hPseRFyb42H2P87VDx9h4/gp+730/zM+9ZaPHnEsqFMO9wc7Hj/DbX/w2MzPJ773vh/nAWzd5xIukQjLcgdGTU9zxwHd44LEjvHnzaj7xgau5+ILBTpclSa9a14f7Nw4d46P3Pc7Toyf56PWX86vXXUafq3VJBdfV4f5HDz3JH3z5CS5es5L7/8WPcs3m8ztdkiS1RdeG+xceGeb3/+oJbrz6Iv7Dz/x9Bj3Hi6QS6cpE+9bwC9z+xW/zY5ddwB+8/022YSSVTtel2shLk3zoM48wtGqAP/r5Nxvskkqpq1bulekZfvWzj3B8vMIXfuXHWDPY3+mSJGlJdFW4//u/3Mfu7x3nD2++hqsuOq/T5UjSkumansS93/w+n/n6U3zo7Zdyw5su6nQ5krSkuiLcH3nqOHd8aS//cOtafmvHD3W6HElacqUP96nqDB/+7N+x/rzlfPLmazw9r6SuUPpw/+7ICZ4ePclHrt/K6pV+gSqpO5Q+3PcfHQXwC1RJXaULwv0l+vt6uHStJwKT1D26INxHuWLdOf5YSVJXKX3i7T86ypUXntPpMiTprCp1uD/70kmeO1HhygvP7XQpknRWlTrc9x99CcBwl9R1Sh3u+47UjpS5cr3hLqm7tBTuEbEjIg5ExMGIuK3J4xdHxFci4lsR8dWI2Nj+Us/c/qOjbFi9gvNWLut0KZJ0Vi0a7hHRC9wFvBvYBtwcEdvmDPt94M8y843AncB/bHehr4ZfpkrqVq2s3K8FDmbmocysAPcCN84Zsw34Sv3+w00eP+tOTlU59NyY/XZJXamVcN8AHG7YHq7va/Q48LP1+z8DnBMRF7z28l69J585QXUmDXdJXamVcG92pq2cs/0bwDsi4lHgHcAPgOnTXijilojYExF7RkZGzrjYMzF72oFthrukLtRKuA8Dmxq2NwJHGgdk5pHM/MeZeQ3w2/V9L859ocy8OzO3Z+b2oaGh11D24vYdHWWwv5fNa1Yu6ftI0utRK+G+G9gaEZdERD9wE7CzcUBErI2I2de6HbinvWWeuX1HR7li/Tn0eIpfSV1o0XDPzGngVuBBYD9wX2bujYg7I+KG+rDrgAMR8QSwDvj4EtXbksysHyljS0ZSd2rpGqqZuQvYNWffHQ337wfub29pr94PXpjgpZPThrukrlXKX6h62gFJ3a6k4T5KBPzQen/AJKk7lTbcL16zksGBlrpOklQ6pQz3fUdH2XaRLRlJ3at04X5icpqnjo17JkhJXa104X7g6fppfv0yVVIXK12475s9Usa2jKQuVrpw3390lHOX93HRecs7XYokdUwpw/3KC88lwtMOSOpepQr36kxy4OmX7LdL6nqlCvenjo0xXql6ml9JXa9U4e5pBySppmThPkpvT7B13apOlyJJHVW6cL9saJDly3o7XYokdVTpwt2WjCSVKNxfGK9w5MWThrskUaJwP/jsCQCuWOdpfiWpNOE+enIKgPMH+ztciSR1XmnCfbxSBWBlv1+mSlJ5wn2yFu4rPFJGkkoU7pVpAK++JEmUKdynbMtI0qzShPtEpUoEDPSVZkqS9KqVJgnHJqsM9vd5ql9JokThPjE1zQpbMpIElCjcxytV++2SVFeacB+brLKy3yNlJAlaDPeI2BERByLiYETc1uTxzRHxcEQ8GhHfioj3tL/UhU1MTbtyl6S6RcM9InqBu4B3A9uAmyNi25xh/wa4LzOvAW4C/mu7C12MbRlJekUrK/drgYOZeSgzK8C9wI1zxiQwezrG84Aj7SuxNeOThrskzWol3DcAhxu2h+v7Gv0u8AsRMQzsAn6t2QtFxC0RsSci9oyMjLyKcuc3PjVtz12S6loJ92YHjuec7ZuBT2XmRuA9wGci4rTXzsy7M3N7Zm4fGho682oXMFGpeiikJNW1Eu7DwKaG7Y2c3nb5JeA+gMz8GrAcWNuOAltV+xGT4S5J0Fq47wa2RsQlEdFP7QvTnXPGfB/4SYCIuJJauLe377KAmZlkYqrKCtsykgS0EO6ZOQ3cCjwI7Kd2VMzeiLgzIm6oD/sY8MsR8TjwOeCDmTm3dbNkTk570jBJatTSUjczd1H7orRx3x0N9/cBb2tvaa0bq5/L3baMJNWU4heqE/WrMNmWkaSaUoT7+FTtQh22ZSSpphThPtuWMdwlqaYU4T7x8sWxbctIEpQk3Gevn+rKXZJqShLutmUkqVHJwt22jCRBacK91pbx3DKSVFOScLctI0mNShPu/b09LOstxXQk6TUrRRpOVKZtyUhSg1KE+1jF0/1KUqNShLsX6pCkU5Ui3McrXmJPkhqVItzHKl4cW5IalSLcJwx3STpFKcLdtowknaok4e7KXZIaGe6SVEKlCPfaoZC2ZSRpVuHDfao6Q6U644+YJKlB4cN9/OWLYxvukjSr8OHuJfYk6XSFD/fZc7kPDrhyl6RZJQj3eltmmeEuSbNKE+62ZSTpFS2Fe0TsiIgDEXEwIm5r8vgnIuKx+t8TEfFC+0ttbrYts9K2jCS9bNHlbkT0AncB1wPDwO6I2JmZ+2bHZOZHGsb/GnDNEtTalJfYk6TTtbJyvxY4mJmHMrMC3AvcuMD4m4HPtaO4Vrwc7stsy0jSrFbCfQNwuGF7uL7vNBFxMXAJ8NBrL601E7ZlJOk0rYR7NNmX84y9Cbg/M6tNXyjilojYExF7RkZGWq1xQWO2ZSTpNK2E+zCwqWF7I3BknrE3sUBLJjPvzsztmbl9aGio9SoXMNuWWd5nuEvSrFbCfTewNSIuiYh+agG+c+6giLgCOB/4WntLXNhEZZqV/b309DT7PxiS1J0WDffMnAZuBR4E9gP3ZebeiLgzIm5oGHozcG9mzteyWRJeYk+STtfSISaZuQvYNWffHXO2f7d9ZbWudrpfw12SGpXgF6rTDPrrVEk6RQnC3ZW7JM1VinC35y5JpypJuNuWkaRGJQj3aVfukjRHCcLdtowkzVX4cJ+wLSNJpyl0uGcmY7ZlJOk0hQ73yekZMvFQSEmao9DhPnvSMH/EJEmnKnS4j03WzuXuyl2STlXocJ+Y8lzuktRMocPdtowkNVfscLctI0lNFTvcvcSeJDVV7HB/ueduW0aSGhU73OttGVfuknSqYoe7bRlJaqrQ4T5hW0aSmip0uI9NTtPXE/T3FXoaktR2hU5FL7EnSc0VOtwnKlV/wCRJTRQ63D3dryQ1V+hwn7AtI0lNFTrcvcSeJDVX8HCf9jBISWqi4OHuyl2Smmkp3CNiR0QciIiDEXHbPGP+SUTsi4i9EfHn7S2zOQ+FlKTmFu1pREQvcBdwPTAM7I6InZm5r2HMVuB24G2ZeTwi3rBUBTeamPJQSElqppWV+7XAwcw8lJkV4F7gxjljfhm4KzOPA2Tms+0ts7mxSQ+FlKRmWgn3DcDhhu3h+r5GlwOXR8T/joivR8SOZi8UEbdExJ6I2DMyMvLqKq6rziST0zO2ZSSpiVbCPZrsyznbfcBW4DrgZuBPI2L1aU/KvDszt2fm9qGhoTOt9RSzJw2zLSNJp2sl3IeBTQ3bG4EjTcZ8KTOnMvP/AQeohf2S8RJ7kjS/VsJ9N7A1Ii6JiH7gJmDnnDEPAD8BEBFrqbVpDrWz0Lk8l7skzW/RcM/MaeBW4EFgP3BfZu6NiDsj4ob6sAeBYxGxD3gY+M3MPLZURUNjuNuWkaS5WkrGzNwF7Jqz746G+wl8tP53VoxXvMSeJM2nsL9QtS0jSfMrQbjblpGkuQoc7rZlJGk+BQ532zKSNJ/ChvvEbLgP2JaRpLkKG+5j9bbMimWu3CVprsKG+0SlykBfD709zc6OIEndrbDhPl6pMmhLRpKaKmy4j1WmbclI0jwKG+4TXmJPkuZV2HAfr1Q9UkaS5lHgcJ9mpW0ZSWqqwOFuW0aS5lPYcJ+wLSNJ8ypsuI/ZlpGkeRU23McrVS+xJ0nzKGS4ZyYTlSqDA4a7JDVTyHCvVGeYnknP5S5J8yhkuM+eEdJfqEpSc4UM99lzuduWkaTmChru9dP92paRpKYKGu71C3XYlpGkpood7rZlJKmpgob77MWxbctIUjMFDXcvji1JCzHcJamEWgr3iNgREQci4mBE3Nbk8Q9GxEhEPFb/++ftL/UV45O2ZSRpIYumY0T0AncB1wPDwO6I2JmZ++YM/Xxm3roENZ5mfMqVuyQtpJWV+7XAwcw8lJkV4F7gxqUta2ETlSo9AQN9hewqSdKSayUdNwCHG7aH6/vm+tmI+FZE3B8Rm9pS3TzGJqus7O8jIpbybSSpsFoJ92YJmnO2/wewJTPfCPxP4NNNXyjilojYExF7RkZGzqzSBhNT057uV5IW0Eq4DwONK/GNwJHGAZl5LDMn65v/DXhLsxfKzLszc3tmbh8aGno19QK1o2UGDXdJmlcr4b4b2BoRl0REP3ATsLNxQERc2LB5A7C/fSWernahDo+UkaT5LJqQmTkdEbcCDwK9wD2ZuTci7gT2ZOZO4F9GxA3ANPA88MElrJnxyrRHykjSAlpa/mbmLmDXnH13NNy/Hbi9vaXNb7xSZZUXx5akeRXyWMKJStWVuyQtoJDhPlaZ9tepkrSAQoa7K3dJWlghw33ccJekBRUu3Gdm0kMhJWkRhQv3k9P1i2O7cpekeRUu3D2XuyQtrnjhPlkLd9sykjS/4oX7VO1CHbZlJGl+xQv3yuzK3XCXpPkUL9wnZ3vutmUkaT7FC/fK7PVTXblL0nwKF+4TXj9VkhZVuHAfsy0jSYsqXLi/3JYZcOUuSfMpXLhvXrOSHVetZ+Uyw12S5lO43sa7rlrPu65a3+kyJOl1rXArd0nS4gx3SSohw12SSshwl6QSMtwlqYQMd0kqIcNdkkrIcJekEorM7MwbR4wAT73Kp68FnmtjOUXRrfOG7p278+4urcz74swcWuyFOhbur0VE7MnM7Z2u42zr1nlD987deXeXds7btowklZDhLkklVNRwv7vTBXRIt84bunfuzru7tG3ehey5S5IWVtSVuyRpAYUL94jYEREHIuJgRNzW6XqWSkTcExHPRsR3GvatiYgvR8ST9dvzO1njUoiITRHxcETsj4i9EfHr9f2lnntELI+Ib0bE4/V5/7v6/ksi4hv1eX8+Ivo7XetSiIjeiHg0Iv6yvl36eUfE9yLi2xHxWETsqe9r2+e8UOEeEb3AXcC7gW3AzRGxrbNVLZlPATvm7LsN+EpmbgW+Ut8um2ngY5l5JfAjwIfr/xuXfe6TwDsz803A1cCOiPgR4D8Bn6jP+zjwSx2scSn9OrC/Ybtb5v0TmXl1w+GPbfucFyrcgWuBg5l5KDMrwL3AjR2uaUlk5t8Az8/ZfSPw6fr9TwPvO6tFnQWZeTQz/65+/yVq/+A3UPK5Z82J+uay+l8C7wTur+8v3bwBImIj8I+AP61vB10w73m07XNetHDfABxu2B6u7+sW6zLzKNRCEHhDh+tZUhGxBbgG+AZdMPd6a+Ix4Fngy8B3gRcyc7o+pKyf9/8C/BYwU9++gO6YdwJ/FRGPRMQt9X1t+5wX7Rqq0WSfh/uUUESsAr4A/KvMHK0t5sotM6vA1RGxGvgicGWzYWe3qqUVEe8Fns3MRyLiutndTYaWat51b8vMIxHxBuDLEfF/2/niRVu5DwObGrY3Akc6VEsnPBMRFwLUb5/tcD1LIiKWUQv2z2bmX9R3d8XcATLzBeCr1L5zWB0Rs4uwMn7e3wbcEBHfo9ZmfSe1lXzZ501mHqnfPkvtP+bX0sbPedHCfTewtf5Nej9wE7CzwzWdTTuBX6zf/0XgSx2sZUnU+63/Hdifmf+54aFSzz0ihuordiJiBfBT1L5veBj4ufqw0s07M2/PzI2ZuYXav+eHMvOfUvJ5R8RgRJwzex94F/Ad2vg5L9yPmCLiPdT+y94L3JOZH+9wSUsiIj4HXEftLHHPAL8DPADcB2wGvg+8PzPnfulaaBHx48DfAt/mlR7sv6bWdy/t3CPijdS+QOultui6LzPvjIhLqa1o1wCPAr+QmZOdq3Tp1Nsyv5GZ7y37vOvz+2J9sw/488z8eERcQJs+54ULd0nS4orWlpEktcBwl6QSMtwlqYQMd0kqIcNdkkrIcJekEjLcJamEDHdJKqH/D8PVfZAEZIwBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history3.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.97      0.96      0.96      1032\n",
      "          3       0.94      0.95      0.95      1010\n",
      "          4       0.97      0.96      0.97       982\n",
      "          5       0.96      0.95      0.95       892\n",
      "          6       0.97      0.97      0.97       958\n",
      "          7       0.97      0.97      0.97      1028\n",
      "          8       0.95      0.96      0.95       974\n",
      "          9       0.95      0.95      0.95      1009\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9641"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test data：\")\n",
    "print(classification_report(y_test.argmax(1), model3.predict(x_test).argmax(1)))\n",
    "metrics.accuracy_score(y_test.argmax(1), model3.predict(x_test).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神經網路可能會有overfitting的問題，加入dropout跟early stopping來防止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dense(100,input_dim = 784))\n",
    "model4.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dense(500))\n",
    "model4.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dense(250))\n",
    "model4.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.003),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                2510      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 256,760\n",
      "Trainable params: 256,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 3s 63us/step - loss: 5.4513 - acc: 0.6399 - val_loss: 2.7805 - val_acc: 0.8150\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 2.7380 - acc: 0.8023 - val_loss: 0.8102 - val_acc: 0.9233\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 1.0463 - acc: 0.8615 - val_loss: 0.3190 - val_acc: 0.9317\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.6026 - acc: 0.8713 - val_loss: 0.2538 - val_acc: 0.9382\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.4619 - acc: 0.8879 - val_loss: 0.2153 - val_acc: 0.9453\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.4013 - acc: 0.8994 - val_loss: 0.1956 - val_acc: 0.9498\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.3609 - acc: 0.9068 - val_loss: 0.1792 - val_acc: 0.9528\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.3262 - acc: 0.9132 - val_loss: 0.1820 - val_acc: 0.9513\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.3087 - acc: 0.9168 - val_loss: 0.1651 - val_acc: 0.9537\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.2917 - acc: 0.9211 - val_loss: 0.1606 - val_acc: 0.9567\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.2728 - acc: 0.9248 - val_loss: 0.1552 - val_acc: 0.9563\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.2649 - acc: 0.9271 - val_loss: 0.1541 - val_acc: 0.9597\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.2570 - acc: 0.9286 - val_loss: 0.1462 - val_acc: 0.9573\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.2440 - acc: 0.9317 - val_loss: 0.1463 - val_acc: 0.9588\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.2315 - acc: 0.9354 - val_loss: 0.1400 - val_acc: 0.9608\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 3s 50us/step - loss: 0.2279 - acc: 0.9353 - val_loss: 0.1380 - val_acc: 0.9615\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.2188 - acc: 0.9366 - val_loss: 0.1306 - val_acc: 0.9642\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.2149 - acc: 0.9389 - val_loss: 0.1307 - val_acc: 0.9638\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.2070 - acc: 0.9409 - val_loss: 0.1299 - val_acc: 0.9637\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.2064 - acc: 0.9418 - val_loss: 0.1267 - val_acc: 0.9633\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1969 - acc: 0.9431 - val_loss: 0.1239 - val_acc: 0.9650\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1941 - acc: 0.9440 - val_loss: 0.1240 - val_acc: 0.9647\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1878 - acc: 0.9453 - val_loss: 0.1210 - val_acc: 0.9643\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1849 - acc: 0.9465 - val_loss: 0.1213 - val_acc: 0.9643\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1865 - acc: 0.9457 - val_loss: 0.1160 - val_acc: 0.9672\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.1791 - acc: 0.9481 - val_loss: 0.1152 - val_acc: 0.9665\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1819 - acc: 0.9472 - val_loss: 0.1162 - val_acc: 0.9668\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1743 - acc: 0.9496 - val_loss: 0.1148 - val_acc: 0.9672\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1704 - acc: 0.9503 - val_loss: 0.1115 - val_acc: 0.9675\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1627 - acc: 0.9514 - val_loss: 0.1117 - val_acc: 0.9688\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.1589 - acc: 0.9518 - val_loss: 0.1101 - val_acc: 0.9678\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1607 - acc: 0.9533 - val_loss: 0.1096 - val_acc: 0.9687\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.1540 - acc: 0.9539 - val_loss: 0.1085 - val_acc: 0.9688\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1559 - acc: 0.9542 - val_loss: 0.1073 - val_acc: 0.9683\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1528 - acc: 0.9537 - val_loss: 0.1067 - val_acc: 0.9678\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1532 - acc: 0.9549 - val_loss: 0.1075 - val_acc: 0.9702\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1485 - acc: 0.9563 - val_loss: 0.1055 - val_acc: 0.9700\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1418 - acc: 0.9575 - val_loss: 0.1033 - val_acc: 0.9700\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1437 - acc: 0.9567 - val_loss: 0.1042 - val_acc: 0.9693\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.1437 - acc: 0.9577 - val_loss: 0.1040 - val_acc: 0.9703\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1391 - acc: 0.9584 - val_loss: 0.1013 - val_acc: 0.9692\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1377 - acc: 0.9588 - val_loss: 0.1029 - val_acc: 0.9693\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.1392 - acc: 0.9583 - val_loss: 0.1048 - val_acc: 0.9697\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.1343 - acc: 0.9592 - val_loss: 0.1005 - val_acc: 0.9713\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1335 - acc: 0.9604 - val_loss: 0.1019 - val_acc: 0.9705\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1294 - acc: 0.9607 - val_loss: 0.1005 - val_acc: 0.9695\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1281 - acc: 0.9610 - val_loss: 0.1019 - val_acc: 0.9682\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 3s 52us/step - loss: 0.1278 - acc: 0.9616 - val_loss: 0.1016 - val_acc: 0.9697\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1292 - acc: 0.9608 - val_loss: 0.1011 - val_acc: 0.9715\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.1266 - acc: 0.9625 - val_loss: 0.1008 - val_acc: 0.9705\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train, y_train, batch_size=100, epochs=50, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 雖然train data時的表現看似變差了，但對validation跟test data的效果較好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data：\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       980\n",
      "          1       0.98      0.99      0.99      1135\n",
      "          2       0.96      0.97      0.97      1032\n",
      "          3       0.95      0.97      0.96      1010\n",
      "          4       0.96      0.97      0.97       982\n",
      "          5       0.96      0.94      0.95       892\n",
      "          6       0.96      0.97      0.97       958\n",
      "          7       0.97      0.96      0.96      1028\n",
      "          8       0.96      0.95      0.96       974\n",
      "          9       0.97      0.94      0.95      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9667"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test data：\")\n",
    "print(classification_report(y_test.argmax(1), model4.predict(x_test).argmax(1)))\n",
    "metrics.accuracy_score(y_test.argmax(1), model4.predict(x_test).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 互動小程式可以觀察神經網路預測每筆資料的成果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model4.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(測試編號):\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28), cmap='Greys')\n",
    "    print('原本給的label為：', y_test.argmax(1)[測試編號])\n",
    "    print('神經網路判斷為:',predict[測試編號])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a8cc946aa74167a64d6eacd63f714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='測試編號', max=9999), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(測試編號)>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(test, 測試編號=(0,9999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將訓練好的神經網路存起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('hand_writing.json', 'w').write(model_json)\n",
    "model.save_weights('hand_writing_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
